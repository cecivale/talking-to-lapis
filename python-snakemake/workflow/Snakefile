
# ----------------------------------------------------------------------------------
#          ---        
#        / o o \    Snakemake workflow talking to LAPIS
#        V\ Y /V    Rules to load sequence data and other metadata with LAPIS
#    (\   / - \     
#     )) /    |     
#     ((/__) ||     Code by Ceci VA 
# -----------------------------------------------------------------------------------

import os 

from snakemake.utils import update_config, validate, min_version
min_version("7.11.0")

configfile: "config.yaml"

# envvars:
#     config["lapis"]["access_key"]

localrules: all, clean

DATASETS = list(config["datasets"].keys())


rule all:
    input:
        expand("results/{dataset}/data/aligned.fasta", dataset = DATASETS)

rule clean:
    shell:
        '''
        rm -rf results logs
        '''

rule load_metadata:
    message:
        """
        Load with LAPIS sequences metadata from config file.
        """
    output:
        ids = "results/data/{dataset}/{prefix,.*}ids.tsv",
        metadata = "results/data/{dataset}/{prefix,.*}metadata.tsv"
    # params:
    #     x=os.environ[config["lapis"]["access_key"]]
    log:
        "logs/load_metadata_{dataset}{prefix,.*}.txt"
    conda:
        "envs/python-genetic-data.yaml"
    shell:
        """
        python3 workflow/scripts/lapis_query_metadata.py \
            --select config["dataset"][wildcards.dataset][wildcards.deme]['select'] \
            --output_metadata {output.metadata} \
            --output_ids {output.ids}  2>&1 | tee {log}
        """

def _is_structured(wildcards):
    return (config["dataset"][wildcards.dataset].get("structure") is not None)

def _get_ids_to_combine(wildcards):
    if _is_structured(wildcards):
        demes = config["dataset"][wildcards.dataset]["structure"].keys()
        files = expand("results/{{dataset}}/data/{deme}/ids.tsv", deme = demes)
    else:
        files = "results/{dataset}/data/ids.tsv"
    return files

rule combine_samples:
    message:
        """
        Combine sequences metadata from demes.
        """
    input:
        ids = _get_ids_to_combine
    output:
        ids = "results/{dataset}/data/ids_combined.tsv" 
    log:
        "logs/combine_ids_{dataset}.txt"
    shell:
        """
        rm -f {output.ids}
        awk '(NR == 1) || (FNR > 1)' {input.ids} > {output.ids} 2>&1 | tee {log}
        """

def  _get_sequences_ids(wildcards):
    data_dir = "results/data/{dataset}/"
    return (data_dir + "ids_combined.tsv" if _is_structured(wildcards) else data_dir + "ids.tsv")

def  _get_lapis_param(param, wildcards):
    return config["lapis"][param]

rule load_sequences: # TODO access_key
    message:
        """
        Load with LAPIS the selected sequences for each dataset and drop not full genome sequences.
        """
    input:
        ids = _get_sequences_ids
    output:
        alignment = "results/data/{dataset}/aligned.fasta"
    params:
        database = lambda wildcards: _get_lapis_param("database", wildcards),
        seq_id = lambda wildcards: _get_lapis_param("seq_id", wildcards),
        drop_incomplete = False,
        batch_size = 100,
        # access_key = os.environ[config["lapis"]["access_key"]] or ""
    log:
        "logs/load_seqs_{dataset}.txt" 
    conda:
        "envs/python-genetic-data.yaml"
    script:
        "scripts/query_sequences.py"

# """
# python3 workflow/scripts/lapis_query_sequences.py \
#     --database "{params.database}" \
#     --seq_id "{params.seq_id}" \
#     --ids_file {input.ids} \
#     --output_file {output.alignment} \
#     --drop_incomplete {params.drop_incomplete} 2>&1 | tee {log}
# """
