
# ----------------------------------------------------------------------------------
#          ---        
#        / o o \    Snakemake workflow talking to LAPIS
#        V\ Y /V    Rules to load sequence data and other metadata with LAPIS
#    (\   / - \     
#     )) /    |     
#     ((/__) ||     Code by Ceci VA 
# -----------------------------------------------------------------------------------

import os 

from snakemake.utils import update_config, validate, min_version
min_version("7.11.0")

configfile: "config.yaml"

envvars:
    config["lapis"]["access_key"]

localrules: all, clean
# wildcards
wildcard_constraints:
    dataset="[A-Za-z0-9_]+"

DATASETS = list(config["datasets"].keys())


rule all:
    input:
        expand("results/data/{dataset}/aligned.fasta", dataset = DATASETS)

rule clean:
    shell:
        '''
        rm -rf results logs
        '''

def _is_structured(wildcards):
    return (config["datasets"][wildcards.dataset].get("structure") is not None)

def  _get_dataset_param(param, wildcards):
    if _is_structured(wildcards):
        return config["datasets"][wildcards.dataset]["structure"][wildcards.prefix[0:-1]].get(param)
    else:
        return config["datasets"][wildcards.dataset].get(param)

def  _get_select_params(wildcards):
    return _get_dataset_param("select", wildcards)

def _get_deme(wildcards):
    if _is_structured(wildcards):
        return config["datasets"][wildcards.dataset]["structure"][wildcards.prefix[0:-1]].get("deme", 
            wildcards.prefix[0:-1]) 
    else:
        return None

rule load_metadata:
    message:
        """
        Load with LAPIS sequences metadata from config file.
        """
    output:
        ids = "results/data/{dataset}/{prefix,.*}ids.tsv",
        metadata = "results/data/{dataset}/{prefix,.*}metadata.tsv"
    params:
        database = config["lapis"]["database"],
        access_key = os.environ[config["lapis"]["access_key"]],
        seq_id = config["lapis"]["seq_id"],
        deme = lambda wildcards: _get_deme(wildcards)
    log:
        "logs/load_metadata_{dataset}{prefix,.*}.txt"
    conda:
        "envs/python-genetic-data.yaml"
    script:
        "scripts/query_metadata.py"


def _get_ids_to_combine(wildcards):
    if _is_structured(wildcards):
        demes = config["datasets"][wildcards.dataset]["structure"].keys()
        files = expand("results/data/{{dataset}}/{deme}/ids.tsv", deme = demes)
    else:
        files = "results/data/{dataset}/ids.tsv"
    return files

rule combine_samples:
    message:
        """
        Combine sequences metadata from demes.
        """
    input:
        ids = _get_ids_to_combine
    output:
        ids = "results/data/{dataset}/ids_combined.tsv" 
    log:
        "logs/combine_ids_{dataset}.txt"
    shell:
        """
        rm -f {output.ids}
        awk '(NR == 1) || (FNR > 1)' {input.ids} > {output.ids} 2>&1 | tee {log}
        """

def  _get_sequences_ids(wildcards):
    data_dir = "results/data/{dataset}/"
    return (data_dir + "ids_combined.tsv" if _is_structured(wildcards) else data_dir + "ids.tsv")

def  _get_lapis_param(param, wildcards):
    return config["lapis"][param]

rule load_sequences: # TODO access_key # TODO save sequence version in log # TODO check if it works with --use-conda
    message:
        """
        Load with LAPIS the selected sequences for each dataset.
        """
    input:
        ids = _get_sequences_ids
    output:
        alignment = "results/data/{dataset}/aligned.fasta"
    params:
        database = lambda wildcards: _get_lapis_param("database", wildcards),
        seq_id = lambda wildcards: _get_lapis_param("seq_id", wildcards),
        drop_incomplete = True,
        batch_size = config["lapis"]["batch_size"],
        access_key = os.environ[config["lapis"]["access_key"]] or ""
    log:
        "logs/load_seqs_{dataset}.txt" 
    conda:
        "envs/python-genetic-data.yaml"
    script:
        "scripts/query_sequences.py"

